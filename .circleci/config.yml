version: 2

defaults: &defaults
  docker:
    - image: circleci/python:3.7.2
  working_directory: ~/project

prepare_venv: &prepare_venv
  run:
    name: Create venv
    command: |
      python3 -m venv venv
      source venv/bin/activate
      pip install --upgrade pip

fetch_data: &fetch_data
  run:
    name: Set script permissions and fetch data
    command: |
      source venv/bin/activate
      chmod +x ./scripts/fetch_kaggle_dataset.sh
      ./scripts/fetch_kaggle_dataset.sh

install_model_requirements: &install_model_requirements
    run:
      name: Install model requirements
      command: |
        . venv/bin/activate
        pip install -r packages/regression_model/requirements.txt

train_model: &train_model
    run:
      name: Train model
      command: |
        . venv/bin/activate
        PYTHONPATH=./packages/regression_model python3 packages/regression_model/regression_model/train_pipeline.py

jobs:
  test_regression_model:
    <<: *defaults
    steps:
      - checkout
      - *prepare_venv
      - *install_model_requirements
      - *fetch_data
      - *train_model
      - run:
          name: Run tests
          command: |
            . venv/bin/activate
            py.test -vv packages/regression_model/tests
      - persist_to_workspace:
          # Keep the model object that has been built for future tests
          root: packages/regression_model/regression_model
          # Relative path from root
          paths:
            - datasets/test.csv
            - trained_models

  test_ml_api:
    <<: *defaults
    steps:
      - checkout
      - restore_cache:
          keys:
            - py-deps-{{ checksum "packages/ml_api/requirements.txt" }}
      - attach_workspace:
          # Get workspace following model training step
          at: ~/project/packages/regression_model/regression_model
      - *prepare_venv
      - run:
          name: Runnning tests
          command: |
            . venv/bin/activate
            pip install -r packages/ml_api/requirements.txt
            py.test -vv packages/ml_api/tests -m "not differential"
      - save_cache:
          key: py-deps-{{ checksum "packages/ml_api/requirements.txt" }}
          paths:
            - "/venv"

  train_and_upload_regression_model:
    <<: *defaults
    steps:
      - checkout
      - attach_workspace:
          # Get workspace following model training step
          at: ~/project/packages/regression_model/regression_model
      - *prepare_venv
      - run: 
          name: Publish model to Gemfury
          command: |
            . venv/bin/activate
            # AB note: Section 8.4 recommends using GemFury, but I decided not to. The following line is therefore commented out
            # chmod +x ./scripts/publish_model.sh
            # ./scripts/publish_model.sh ./packages/regression_model/

  section_9_differential_tests:
    <<: *defaults
    steps:
      - checkout
      - attach_workspace:
          # Get workspace following model training step
          at: ~/project/packages/regression_model/regression_model
      - *prepare_venv
      - run:
          name: Capturing previous model predictions
          command: |
            . venv/bin/activate
            pip install -r packages/ml_api/diff_test_requirements.txt
            PYTHONPATH=./packages/ml_api python3 packages/ml_api/tests/capture_model_predictions.py
      - run:
          name: Runnning differential tests
          command: |
            . venv/bin/activate
            pip install -r packages/ml_api/requirements.txt
            py.test -vv packages/ml_api/tests -m differential

  section_10_deploy_to_heroku:
    <<: *defaults
    steps:
      - checkout
      - run:
          name: Deploy to Heroku
          command: |
            git push https://heroku:$HEROKU_API_KEY@git.heroku.com/$HEROKU_APP_NAME.git master_AB:master
  
  section_11_build_and_push_to_heroku_docker:
    <<: *defaults
    steps:
      - checkout
      # The following is a feature of CircleCI that allows docker images to be built
      # See: <https://circleci.com/docs/2.0/building-docker-images/>
      - setup_remote_docker
      # 'registry.heroku.com' is a store of Docker images, as opposed to DockerHub
      - run: 
          name: Login to docker registry
          command: | 
            docker login --username=$HEROKU_EMAIL --password=$HEROKU_API_KEY registry.heroku.com
      - run:
          # Need to install Heroku CLI, so that we can run "heroku container:release" below
          name: Setup Heroku CLI
          command: |
            wget -qO- https://cli-assets.heroku.com/install-ubuntu.sh | sh
      - run: 
          name: Build and Push Image
          # Uses the Makefile
          command: |
            make build-ml-api-heroku push-ml-api-heroku
      - run: 
          name: Release to Heroku
          command: |
            heroku container:release web --app $HEROKU_APP_NAME

  section_12_publish_docker_image_to_aws:
    # AB: I have not signed up to AWS, so this task has never been run (and won't work if it were run)
    <<: *defaults
    working_directory: ~/project/packages/ml_models
    steps:
      - checkout
      - setup_remote_docker
      - run:
          name: Publishing docker image to aws ECR
          command: |
            sudo pip install awscli
            eval $(aws ecr get-login --no-include-email --region us-east-1)
            make build-ml-api-aws tag-ml-api push-ml-api-aws
            aws ecs update-service --cluster ml-api-cluster --service custom-service --task-definition  first-run-task-definition --force-new-deployment

  section_13_train_and_upload_neural_network_model:
    docker:
      - image: circleci/python:3.6.4-stretch
    working_directory: ~/project
    steps:
      - checkout
      - *prepare_venv
      - run: 
          name: Install requirements
          command: |
            . venv/bin/activate
            pip install -r packages/neural_network_model/requirements.txt
      - run:
          name: Fetch Training data - 2GB
          command: |
            . venv/bin/activate
            chmod +x ./scripts/fetch_kaggle_large_dataset.sh
            ./scripts/fetch_kaggle_large_dataset.sh
      - run: 
          name: Train model
          command: |
            . venv/bin/activate
            PYTHONPATH=./packages/neural_network_model python3 packages/neural_network_model/neural_network_model/train_pipeline.py
      - run: 
          name: Publish model to Gemfury
          command: |
            . venv/bin/activate
            # AB note: Section 8.4 recommends using GemFury, but I decided not to. The following line is therefore commented out
            # chmod +x ./scripts/publish_model.sh
            # ./scripts/publish_model.sh ./packages/neural_network_model/

workflows:
  version: 2
  test-all:
    jobs:
      - test_regression_model
      - test_ml_api:
          requires:
            - test_regression_model
      - section_9_differential_tests:
          requires:
            - test_regression_model      
      - train_and_upload_regression_model:
          requires:
            - test_ml_api
            - section_9_differential_tests
          filters:
            branches:
              only:
                - master_AB
      - section_13_train_and_upload_neural_network_model:
          requires:
            - test_ml_api
            - section_9_differential_tests
          filters:
            branches:
              only:
                # I have not tested that building the NN model package
                # works, so it is unlikely that the CI tests will run properly
                - do_not_want_this_to_run_yet
      # - section_10_deploy_to_heroku:
      #     requires:
      #       - train_and_upload_regression_model
      #     filters:
      #       branches:
      #         only:
      #           - master_AB
      - section_11_build_and_push_to_heroku_docker:
          requires:
            - train_and_upload_regression_model
          filters:
            branches:
              only:
                - master_AB
      # - section_12_publish_docker_image_to_aws:
      #     requires:
      #       - train_and_upload_regression_model
      #     filters:
      #       branches:
      #         only:
      #           - do_not_want_this_to_run_ever
